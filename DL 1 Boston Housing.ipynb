{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6893c6-9847-43c0-8f70-8ef22c4f4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8479199a-9f2f-4583-ae2d-5c2fe541d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\BE\\LP 5 DL\\HousingData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba487144-f8d0-4d92-a479-b7f76ab667e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d647462-709c-4ec3-b45c-cf4e9d422487",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"MEDV\", axis=1).values\n",
    "y = df[\"MEDV\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f8116e7-8a85-4abd-8d1d-b2b0f1bf6f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771d1e2c-5db0-4bc3-8fec-9e09fbcc90bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6a037b-a046-43df-948f-0c4c0f9fb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b37840b-60d0-42e9-9931-a83247dfe588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train Shape : (404, 13)\n",
      "x_test Shape : (102, 13)\n",
      "y_train shape : (404,)\n",
      "y_test shape : (102,)\n"
     ]
    }
   ],
   "source": [
    "def shape():\n",
    "    print(\"x_train Shape :\",x_train.shape)\n",
    "    print(\"x_test Shape :\",x_test.shape)\n",
    "    print(\"y_train shape :\",y_train.shape)\n",
    "    print(\"y_test shape :\",y_test.shape)\n",
    "shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde2206-acb9-4701-9e95-10c20fd320bd",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14309bb9-dae7-4f6d-ba9b-3122ff0ce7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=x_train.mean(axis=0)\n",
    "std=x_train.std(axis=0)\n",
    "x_train=(x_train-mean)/std\n",
    "x_test=(x_test-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68dcd052-5a87-40f0-958a-b1b369bcd75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        nan,         nan,         nan,         nan, -0.89948549,\n",
       "       -0.39592174,         nan,  0.30338551, -0.7326744 , -0.93384523,\n",
       "        0.00410967,  0.39829499,         nan])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e289ca2-08c0-4b12-b1d7-e7b79023544a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a86e4-6916-4576-945e-1e20a65d6168",
   "metadata": {},
   "source": [
    "Building our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69190bb0-3a0e-4023-8fc4-9b04ad4748e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prati\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m1,792\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,113</span> (39.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,113\u001b[0m (39.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,113</span> (39.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,113\u001b[0m (39.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model=Sequential()\n",
    "model.add(Dense(128,activation='relu',input_shape=(x_train[0].shape)))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e973b8a3-59bc-4b0f-a53f-e64089f76286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 569.5123 - mae: 22.0826 - val_loss: 510.2632 - val_mae: 21.1009\n",
      "Epoch 2/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 604.7833 - mae: 22.6566 - val_loss: 494.9854 - val_mae: 20.7357\n",
      "Epoch 3/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 566.3209 - mae: 21.7952 - val_loss: 479.8961 - val_mae: 20.3686\n",
      "Epoch 4/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 579.1381 - mae: 22.1812 - val_loss: 465.2698 - val_mae: 20.0063\n",
      "Epoch 5/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 491.9702 - mae: 20.5534 - val_loss: 450.8618 - val_mae: 19.6430\n",
      "Epoch 6/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 489.8945 - mae: 20.2516 - val_loss: 436.8774 - val_mae: 19.2837\n",
      "Epoch 7/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 572.3845 - mae: 21.6674 - val_loss: 423.3792 - val_mae: 18.9305\n",
      "Epoch 8/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 522.5301 - mae: 20.7149 - val_loss: 410.0491 - val_mae: 18.5751\n",
      "Epoch 9/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 480.3146 - mae: 19.7733 - val_loss: 397.1418 - val_mae: 18.2243\n",
      "Epoch 10/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 485.5518 - mae: 19.7998 - val_loss: 384.5039 - val_mae: 17.8742\n",
      "Epoch 11/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 445.4959 - mae: 18.9278 - val_loss: 372.0463 - val_mae: 17.5223\n",
      "Epoch 12/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 426.7032 - mae: 18.6757 - val_loss: 359.9693 - val_mae: 17.1742\n",
      "Epoch 13/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 425.3683 - mae: 18.3429 - val_loss: 348.1530 - val_mae: 16.8267\n",
      "Epoch 14/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 439.3823 - mae: 18.6818 - val_loss: 336.7109 - val_mae: 16.4832\n",
      "Epoch 15/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 374.8331 - mae: 17.0606 - val_loss: 325.5157 - val_mae: 16.1400\n",
      "Epoch 16/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 383.8079 - mae: 17.2613 - val_loss: 314.5672 - val_mae: 15.7972\n",
      "Epoch 17/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 363.5996 - mae: 16.6226 - val_loss: 303.9387 - val_mae: 15.4571\n",
      "Epoch 18/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 346.4596 - mae: 16.0801 - val_loss: 293.5576 - val_mae: 15.1176\n",
      "Epoch 19/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 363.6877 - mae: 16.5218 - val_loss: 283.5135 - val_mae: 14.7816\n",
      "Epoch 20/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 344.6261 - mae: 16.1859 - val_loss: 273.7690 - val_mae: 14.4483\n",
      "Epoch 21/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 366.3013 - mae: 16.6127 - val_loss: 264.3242 - val_mae: 14.1241\n",
      "Epoch 22/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 344.8801 - mae: 15.6546 - val_loss: 255.1132 - val_mae: 13.8108\n",
      "Epoch 23/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 320.7709 - mae: 15.2491 - val_loss: 246.1666 - val_mae: 13.5017\n",
      "Epoch 24/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 310.0959 - mae: 14.6942 - val_loss: 237.4745 - val_mae: 13.1941\n",
      "Epoch 25/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 255.9393 - mae: 13.5059 - val_loss: 229.0495 - val_mae: 12.8884\n",
      "Epoch 26/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 289.4095 - mae: 14.4080 - val_loss: 220.9529 - val_mae: 12.5872\n",
      "Epoch 27/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 303.4062 - mae: 14.3318 - val_loss: 213.0334 - val_mae: 12.2848\n",
      "Epoch 28/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 294.8432 - mae: 14.0060 - val_loss: 205.4814 - val_mae: 11.9889\n",
      "Epoch 29/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 251.5142 - mae: 13.1691 - val_loss: 198.0580 - val_mae: 11.6901\n",
      "Epoch 30/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 281.2267 - mae: 13.8644 - val_loss: 191.0201 - val_mae: 11.3991\n",
      "Epoch 31/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 221.0267 - mae: 12.0380 - val_loss: 184.1666 - val_mae: 11.1091\n",
      "Epoch 32/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 237.2255 - mae: 12.7502 - val_loss: 177.5965 - val_mae: 10.8292\n",
      "Epoch 33/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 226.0362 - mae: 12.1898 - val_loss: 171.2802 - val_mae: 10.5603\n",
      "Epoch 34/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 248.1986 - mae: 12.5145 - val_loss: 165.2434 - val_mae: 10.2981\n",
      "Epoch 35/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 193.0224 - mae: 11.2976 - val_loss: 159.3722 - val_mae: 10.0368\n",
      "Epoch 36/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 238.5410 - mae: 12.1777 - val_loss: 153.7850 - val_mae: 9.7861\n",
      "Epoch 37/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 204.0985 - mae: 11.5086 - val_loss: 148.3390 - val_mae: 9.5386\n",
      "Epoch 38/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 198.5479 - mae: 10.8604 - val_loss: 143.1985 - val_mae: 9.2974\n",
      "Epoch 39/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 236.1403 - mae: 11.9537 - val_loss: 138.3071 - val_mae: 9.0672\n",
      "Epoch 40/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 173.9579 - mae: 10.1670 - val_loss: 133.5957 - val_mae: 8.8482\n",
      "Epoch 41/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 173.2289 - mae: 10.0803 - val_loss: 129.1237 - val_mae: 8.6436\n",
      "Epoch 42/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 173.0895 - mae: 9.7462 - val_loss: 124.7970 - val_mae: 8.4417\n",
      "Epoch 43/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 179.2665 - mae: 9.9922 - val_loss: 120.7603 - val_mae: 8.2533\n",
      "Epoch 44/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159.4815 - mae: 9.7991 - val_loss: 116.8882 - val_mae: 8.0705\n",
      "Epoch 45/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 168.7537 - mae: 9.9286 - val_loss: 113.2511 - val_mae: 7.8955\n",
      "Epoch 46/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153.8274 - mae: 9.3847 - val_loss: 109.7955 - val_mae: 7.7353\n",
      "Epoch 47/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122.9434 - mae: 8.1955 - val_loss: 106.4754 - val_mae: 7.5870\n",
      "Epoch 48/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127.7077 - mae: 8.4091 - val_loss: 103.3187 - val_mae: 7.4449\n",
      "Epoch 49/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147.9113 - mae: 8.9877 - val_loss: 100.4290 - val_mae: 7.3121\n",
      "Epoch 50/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140.5441 - mae: 8.7628 - val_loss: 97.6726 - val_mae: 7.1903\n",
      "Epoch 51/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136.5088 - mae: 8.6600 - val_loss: 95.0780 - val_mae: 7.0767\n",
      "Epoch 52/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 161.0493 - mae: 9.2413 - val_loss: 92.6592 - val_mae: 6.9668\n",
      "Epoch 53/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120.9064 - mae: 7.9785 - val_loss: 90.3859 - val_mae: 6.8638\n",
      "Epoch 54/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129.6741 - mae: 8.2125 - val_loss: 88.2469 - val_mae: 6.7659\n",
      "Epoch 55/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124.5390 - mae: 8.1416 - val_loss: 86.2655 - val_mae: 6.6745\n",
      "Epoch 56/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145.7749 - mae: 8.3711 - val_loss: 84.4197 - val_mae: 6.5862\n",
      "Epoch 57/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121.1872 - mae: 7.7121 - val_loss: 82.6790 - val_mae: 6.5005\n",
      "Epoch 58/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 99.8815 - mae: 7.2376 - val_loss: 81.0283 - val_mae: 6.4193\n",
      "Epoch 59/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138.9539 - mae: 8.4553 - val_loss: 79.5803 - val_mae: 6.3466\n",
      "Epoch 60/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 104.7039 - mae: 7.3575 - val_loss: 78.1635 - val_mae: 6.2731\n",
      "Epoch 61/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151.6179 - mae: 8.6770 - val_loss: 76.9193 - val_mae: 6.2076\n",
      "Epoch 62/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 114.3587 - mae: 7.5254 - val_loss: 75.7268 - val_mae: 6.1415\n",
      "Epoch 63/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.4957 - mae: 7.3343 - val_loss: 74.6524 - val_mae: 6.0787\n",
      "Epoch 64/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101.7217 - mae: 7.2505 - val_loss: 73.6413 - val_mae: 6.0164\n",
      "Epoch 65/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.2921 - mae: 7.4072 - val_loss: 72.7381 - val_mae: 5.9576\n",
      "Epoch 66/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 102.9471 - mae: 7.1436 - val_loss: 71.8750 - val_mae: 5.9043\n",
      "Epoch 67/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.5465 - mae: 7.0863 - val_loss: 71.1038 - val_mae: 5.8541\n",
      "Epoch 68/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.7778 - mae: 6.8822 - val_loss: 70.4028 - val_mae: 5.8106\n",
      "Epoch 69/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.3403 - mae: 7.0709 - val_loss: 69.7725 - val_mae: 5.7722\n",
      "Epoch 70/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 97.4091 - mae: 6.9698 - val_loss: 69.2037 - val_mae: 5.7393\n",
      "Epoch 71/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 104.7975 - mae: 7.1120 - val_loss: 68.6929 - val_mae: 5.7128\n",
      "Epoch 72/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 94.0258 - mae: 6.8187 - val_loss: 68.2107 - val_mae: 5.6910\n",
      "Epoch 73/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.2726 - mae: 6.8507 - val_loss: 67.7789 - val_mae: 5.6717\n",
      "Epoch 74/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93.6140 - mae: 6.7598 - val_loss: 67.3955 - val_mae: 5.6569\n",
      "Epoch 75/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 107.5705 - mae: 7.0656 - val_loss: 67.0742 - val_mae: 5.6472\n",
      "Epoch 76/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 100.2575 - mae: 6.9448 - val_loss: 66.7669 - val_mae: 5.6408\n",
      "Epoch 77/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 86.2391 - mae: 6.5754 - val_loss: 66.5044 - val_mae: 5.6368\n",
      "Epoch 78/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.9910 - mae: 6.6553 - val_loss: 66.2740 - val_mae: 5.6353\n",
      "Epoch 79/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 96.9886 - mae: 6.9510 - val_loss: 66.0481 - val_mae: 5.6366\n",
      "Epoch 80/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.0289 - mae: 6.6486 - val_loss: 65.8746 - val_mae: 5.6384\n",
      "Epoch 81/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 92.7235 - mae: 6.6310 - val_loss: 65.7042 - val_mae: 5.6403\n",
      "Epoch 82/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.1894 - mae: 6.6606 - val_loss: 65.5680 - val_mae: 5.6427\n",
      "Epoch 83/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.5365 - mae: 6.5148 - val_loss: 65.4519 - val_mae: 5.6460\n",
      "Epoch 84/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 98.3035 - mae: 7.0841 - val_loss: 65.3532 - val_mae: 5.6491\n",
      "Epoch 85/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 90.8598 - mae: 6.6673 - val_loss: 65.2698 - val_mae: 5.6521\n",
      "Epoch 86/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81.8640 - mae: 6.3104 - val_loss: 65.1984 - val_mae: 5.6551\n",
      "Epoch 87/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 86.0985 - mae: 6.6889 - val_loss: 65.1436 - val_mae: 5.6584\n",
      "Epoch 88/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 95.0435 - mae: 6.8391 - val_loss: 65.0978 - val_mae: 5.6626\n",
      "Epoch 89/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 78.9822 - mae: 6.3087 - val_loss: 65.0656 - val_mae: 5.6663\n",
      "Epoch 90/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 93.1220 - mae: 7.0013 - val_loss: 65.0415 - val_mae: 5.6700\n",
      "Epoch 91/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 94.4288 - mae: 6.9176 - val_loss: 65.0260 - val_mae: 5.6736\n",
      "Epoch 92/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 110.1266 - mae: 7.6292 - val_loss: 65.0178 - val_mae: 5.6789\n",
      "Epoch 93/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 89.6946 - mae: 6.6755 - val_loss: 65.0167 - val_mae: 5.6843\n",
      "Epoch 94/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 106.9384 - mae: 7.3700 - val_loss: 65.0217 - val_mae: 5.6908\n",
      "Epoch 95/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.9293 - mae: 6.8725 - val_loss: 65.0313 - val_mae: 5.6967\n",
      "Epoch 96/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 90.3686 - mae: 6.7369 - val_loss: 65.0455 - val_mae: 5.7034\n",
      "Epoch 97/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 105.1782 - mae: 7.0774 - val_loss: 65.0648 - val_mae: 5.7102\n",
      "Epoch 98/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 91.0393 - mae: 6.8476 - val_loss: 65.0876 - val_mae: 5.7175\n",
      "Epoch 99/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 111.8545 - mae: 7.3106 - val_loss: 65.1100 - val_mae: 5.7237\n",
      "Epoch 100/100\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 87.0183 - mae: 6.7802 - val_loss: 65.1385 - val_mae: 5.7305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15c77feb410>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=1, verbose=1,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56f78166-aca8-4a52-83aa-171f40bce059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        nan,         nan,         nan,         nan,  0.2449081 ,\n",
       "       -0.81857266,         nan, -0.46141685,  1.6973528 ,  1.56031821,\n",
       "        0.78814396,  0.40864953,         nan])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae99e45-97c1-4b20-847d-91ce0e996a1a",
   "metadata": {},
   "source": [
    "Testing our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0188619-6d11-4b40-9241-c222c10f5fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Output : 20.1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "Predicted Output : [[21.831886]]\n"
     ]
    }
   ],
   "source": [
    "# test_input=[[-0.42101827, -0.50156705, -1.13081973, -0.25683275, -0.55572682, \n",
    "#              0.19758953, 0.20684755, -0.34272202, -0.87422469, -0.84336666,\n",
    "#              -0.32505625, 0.41244772, -0.63500406]]\n",
    "# print(\"Actual Output :\",y_test[8])\n",
    "# print(\"Predicted Output :\",model.predict(test_input))\n",
    "\n",
    "test_input = [[-0.42101827, -0.50156705, -1.13081973, -0.25683275, -0.55572682,\n",
    "               0.19758953, 0.20684755, -0.34272202, -0.87422469, -0.84336666,\n",
    "              -0.32505625, 0.41244772, -0.63500406]]\n",
    "\n",
    "test_input_np = np.array(test_input)\n",
    "\n",
    "print(\"Actual Output :\", y_test[8])\n",
    "print(\"Predicted Output :\", model.predict(test_input_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f498fceb-8bcb-4563-ae85-f910b02ca11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 59.8402 - mae: 5.5376  \n",
      "Mean squared error on test data : 65.1385269165039\n",
      "Mean absolute error on test data : 5.730491638183594\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "R2 Score : -0.001879120454001626\n"
     ]
    }
   ],
   "source": [
    "mse_nn,mae_nn=model.evaluate(x_test,y_test)\n",
    "print('Mean squared error on test data :',mse_nn)\n",
    "print('Mean absolute error on test data :',mae_nn)\n",
    "from sklearn.metrics import r2_score\n",
    "y_dl=model.predict(x_test)\n",
    "r2=r2_score(y_test,y_dl)\n",
    "print('R2 Score :',r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
